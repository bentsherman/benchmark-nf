manifest {
	mainScript = "main.nf"
	defaultBranch = "master"
	nextflowVersion = ">=20.01.0"
}



env {
	PATH = "${PATH}:${PWD}/bin"
}



params {
	input {
		dir = "hemelb/input"
		gmy_files = "*.gmy"
		xml_files = "*.xml"
		conditions_file = "conditions.txt"
		trials = 5
	}

	output {
		dir = "hemelb/output"
	}
}



report {
	enabled = true
	file = "${params.output.dir}/reports/report.html"
}



timeline {
	enabled = true
	file = "${params.output.dir}/reports/timeline.html"
}



trace {
	enabled = true
	fields = "task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes"
	file = "${params.output.dir}/reports/trace.txt"
	raw = true
}



process {
	errorStrategy = "ignore"
}



profiles {
	standard {
		process {
			executor = "local"
			cpus = 1
			memory = "8 GB"

			afterScript = "rm -rf results"
		}
		executor {
			queueSize = 1
		}
	}

	testing {
		process.errorStrategy = "terminate"
	}

	pbs {
		process {
			executor = "pbspro"
			scratch = false
			time = "12h"

			beforeScript = "module load openmpi/1.10.7; mpirun sleep 10; module rm openmpi"

			withName:run_experiment {
				clusterOptions = {
					(c.gpu_model == "cpu")
					? "-l select=${(c.np.toInteger() + 1).intdiv(2)}:ncpus=4:mpiprocs=2:mem=64gb:interconnect=fdr"
					: "-l select=${(c.np.toInteger() + 1).intdiv(2)}:ncpus=4:mpiprocs=2:mem=64gb:ngpus=2:gpu_model=${c.gpu_model}"
				}
			}
		}
		executor {
			queueSize = 50
		}
	}
}
